{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RL-Basic implementation-Python.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import random"
      ],
      "metadata": {
        "id": "MaoznyxL-0aM"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create Environment class\n",
        "class MyEnvironment:\n",
        "\n",
        "  def __init__(self):\n",
        "    #maximum number of steps which the agent can take to gain rewards\n",
        "    self.remaining_steps=20 #assume that the game must be completed within 20 steps\n",
        "\n",
        "  def get_observation(self):\n",
        "    #it can be any number of coordinates.Its considered as 3 here.\n",
        "    #These values -0.0,0.0,0.0 represent some kind of logic that gives info about the environment.These values can be anything.\n",
        "    return [1.0,2.0,1.0]  \n",
        "  \n",
        "  #when agent,performs an action,it should get a reward\n",
        "  #i have set it as 1 for reward,-1 for punishment\n",
        "  def get_actions(self):\n",
        "    return [-1,1]\n",
        "\n",
        "  #if steps are completed,return True because the agent should not move anymore\n",
        "  def check_is_done(self)->bool:\n",
        "    return self.remaining_steps==0\n",
        "\n",
        "  def action(self,int):\n",
        "    if self.check_is_done():\n",
        "      raise Exception(\"Game over\")      \n",
        "    self.remaining_steps-=1  #if steps can still be taken-game not finished=>decrement the remaining number of steps\n",
        "    return random.random()  #here-as this is a simple implementation-just returning a random number\n",
        "\n",
        "  \n"
      ],
      "metadata": {
        "id": "pYNeebBV_0ud"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#agent implements some policy\n",
        "\n",
        "class myAgent:\n",
        "  def __init__(self):\n",
        "    self.total_rewards=0.0 #initially-agent-no rewards\n",
        "\n",
        "  def step(self,ob:MyEnvironment):\n",
        "    curr_obs=ob.get_observation()\n",
        "    print(curr_obs)\n",
        "    curr_action=ob.get_actions()\n",
        "    print(curr_action)\n",
        "    curr_reward=ob.action(random.choice(curr_action)) \n",
        "    #here,we are randomly picking -1 or 1\n",
        "    #usually,when action() is invoked,implementation to check if the decision of the agent is crt-give positive reward else negative reward\n",
        "    self.total_rewards+=curr_reward\n",
        "    print(\"Total rewards so far= %.3f \"%self.total_rewards)\n"
      ],
      "metadata": {
        "id": "KU9UPugCCe35"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__=='__main__':\n",
        "  obj=MyEnvironment()\n",
        "  agent=myAgent()\n",
        "  step_number=0\n",
        "\n",
        "  while not obj.check_is_done():\n",
        "    step_number+=1\n",
        "    agent.step(obj)\n",
        "    \n",
        "\n",
        "  print(\"Total reward is %.3f \"%agent.total_rewards)\n",
        "  #different o/p everytime we run this code b'coz diff random numbers will be generated"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lI24FW3NEf46",
        "outputId": "d3343782-f385-4882-a8a5-8b762e701045"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1.0, 2.0, 1.0]\n",
            "[-1, 1]\n",
            "Total rewards so far= 0.292 \n",
            "[1.0, 2.0, 1.0]\n",
            "[-1, 1]\n",
            "Total rewards so far= 1.048 \n",
            "[1.0, 2.0, 1.0]\n",
            "[-1, 1]\n",
            "Total rewards so far= 1.142 \n",
            "[1.0, 2.0, 1.0]\n",
            "[-1, 1]\n",
            "Total rewards so far= 1.336 \n",
            "[1.0, 2.0, 1.0]\n",
            "[-1, 1]\n",
            "Total rewards so far= 2.321 \n",
            "[1.0, 2.0, 1.0]\n",
            "[-1, 1]\n",
            "Total rewards so far= 2.917 \n",
            "[1.0, 2.0, 1.0]\n",
            "[-1, 1]\n",
            "Total rewards so far= 3.678 \n",
            "[1.0, 2.0, 1.0]\n",
            "[-1, 1]\n",
            "Total rewards so far= 3.694 \n",
            "[1.0, 2.0, 1.0]\n",
            "[-1, 1]\n",
            "Total rewards so far= 4.344 \n",
            "[1.0, 2.0, 1.0]\n",
            "[-1, 1]\n",
            "Total rewards so far= 4.762 \n",
            "[1.0, 2.0, 1.0]\n",
            "[-1, 1]\n",
            "Total rewards so far= 5.406 \n",
            "[1.0, 2.0, 1.0]\n",
            "[-1, 1]\n",
            "Total rewards so far= 5.613 \n",
            "[1.0, 2.0, 1.0]\n",
            "[-1, 1]\n",
            "Total rewards so far= 6.220 \n",
            "[1.0, 2.0, 1.0]\n",
            "[-1, 1]\n",
            "Total rewards so far= 6.831 \n",
            "[1.0, 2.0, 1.0]\n",
            "[-1, 1]\n",
            "Total rewards so far= 7.400 \n",
            "[1.0, 2.0, 1.0]\n",
            "[-1, 1]\n",
            "Total rewards so far= 8.370 \n",
            "[1.0, 2.0, 1.0]\n",
            "[-1, 1]\n",
            "Total rewards so far= 9.223 \n",
            "[1.0, 2.0, 1.0]\n",
            "[-1, 1]\n",
            "Total rewards so far= 9.324 \n",
            "[1.0, 2.0, 1.0]\n",
            "[-1, 1]\n",
            "Total rewards so far= 10.258 \n",
            "[1.0, 2.0, 1.0]\n",
            "[-1, 1]\n",
            "Total rewards so far= 10.390 \n",
            "Total reward is 10.390 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "BH4y_gnzGpU1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}